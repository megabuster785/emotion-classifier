{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93bbbef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training data:   0%|                                                               | 0/1660 [00:00<?, ?it/s]C:\\Users\\lenovo 6pin\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n",
      "Processing training data: 100%|████████████████████████████████████████████████████| 1660/1660 [04:21<00:00,  6.36it/s]\n",
      "Processing validation data: 100%|████████████████████████████████████████████████████| 416/416 [00:14<00:00, 27.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train_features_augmented_no_sad.npz and val_features_no_sad.npz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Constants\n",
    "DATA_DIR = \"../data\"\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 3\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "MAX_PAD_LEN = 130  # Time steps\n",
    "\n",
    "# Emotion label mapping\n",
    "def get_label_from_filename(filename):\n",
    "    parts = filename.split(\"-\")\n",
    "    emotion = int(parts[2])\n",
    "    emotion_map = {\n",
    "        1: \"neutral\", 2: \"calm\", 3: \"happy\", 4: \"sad\",\n",
    "        5: \"angry\", 6: \"fearful\", 7: \"disgust\", 8: \"surprised\"\n",
    "    }\n",
    "    return emotion_map.get(emotion)\n",
    "\n",
    "# MFCC + Delta + Delta-Delta extraction\n",
    "def extract_mfcc_with_deltas(y, sr, max_pad_len=130, n_mfcc=40):\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    delta1 = librosa.feature.delta(mfcc)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    combined = np.stack([mfcc, delta1, delta2], axis=-1)  # shape: (40, T, 3)\n",
    "\n",
    "    if combined.shape[1] < max_pad_len:\n",
    "        pad_width = max_pad_len - combined.shape[1]\n",
    "        combined = np.pad(combined, ((0, 0), (0, pad_width), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        combined = combined[:, :max_pad_len, :]\n",
    "\n",
    "    return combined\n",
    "\n",
    "# Feature processing with augmentation\n",
    "def process_file(file_path, label, augment=True):\n",
    "    features = []\n",
    "    labels = []\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
    "\n",
    "        # Original\n",
    "        mfcc_orig = extract_mfcc_with_deltas(y, sr)\n",
    "        features.append(mfcc_orig)\n",
    "        labels.append(label)\n",
    "\n",
    "        if augment:\n",
    "            # Add Noise\n",
    "            y_noise = y + 0.005 * np.random.randn(len(y))\n",
    "            mfcc_noise = extract_mfcc_with_deltas(y_noise, sr)\n",
    "            features.append(mfcc_noise)\n",
    "            labels.append(label)\n",
    "\n",
    "            # Time Stretch\n",
    "            try:\n",
    "                y_stretch = librosa.effects.time_stretch(y, rate=0.9)\n",
    "                mfcc_stretch = extract_mfcc_with_deltas(y_stretch, sr)\n",
    "                features.append(mfcc_stretch)\n",
    "                labels.append(label)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Pitch Shift\n",
    "            y_pitch = librosa.effects.pitch_shift(y, sr=sr, n_steps=2)\n",
    "            mfcc_pitch = extract_mfcc_with_deltas(y_pitch, sr)\n",
    "            features.append(mfcc_pitch)\n",
    "            labels.append(label)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed processing {file_path}: {e}\")\n",
    "    return features, labels\n",
    "\n",
    "# Step 1: Gather file paths (excluding 'sad')\n",
    "file_label_pairs = []\n",
    "for folder in [\"Audio_Speech_Actors_01_24\", \"Audio_Songs_Actors_01_24\"]:\n",
    "    full_path = os.path.join(DATA_DIR, folder)\n",
    "    for actor_folder in os.listdir(full_path):\n",
    "        actor_path = os.path.join(full_path, actor_folder)\n",
    "        if not os.path.isdir(actor_path):\n",
    "            continue\n",
    "        for file in os.listdir(actor_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                file_path = os.path.join(actor_path, file)\n",
    "                label = get_label_from_filename(file)\n",
    "                if label and label != \"sad\":  # Drop 'sad'\n",
    "                    file_label_pairs.append((file_path, label))\n",
    "\n",
    "# Step 2: Stratified train/val split\n",
    "labels_only = [lbl for _, lbl in file_label_pairs]\n",
    "train_files, val_files = train_test_split(\n",
    "    file_label_pairs, test_size=0.2, random_state=42, stratify=labels_only\n",
    ")\n",
    "\n",
    "# Step 3: Process train set with augmentation\n",
    "train_data, train_labels = [], []\n",
    "for file_path, label in tqdm(train_files, desc=\"Processing training data\"):\n",
    "    feats, lbls = process_file(file_path, label, augment=True)\n",
    "    train_data.extend(feats)\n",
    "    train_labels.extend(lbls)\n",
    "\n",
    "# Step 4: Process validation set without augmentation\n",
    "val_data, val_labels = [], []\n",
    "for file_path, label in tqdm(val_files, desc=\"Processing validation data\"):\n",
    "    feats, lbls = process_file(file_path, label, augment=False)\n",
    "    val_data.extend(feats)\n",
    "    val_labels.extend(lbls)\n",
    "\n",
    "# Step 5: Save extracted features\n",
    "np.savez(\"../models/train_features_augmented_no_sad.npz\", data=np.array(train_data), labels=np.array(train_labels))\n",
    "np.savez(\"../models/val_features_no_sad.npz\", data=np.array(val_data), labels=np.array(val_labels))\n",
    "\n",
    "print(\"Saved train_features_augmented_no_sad.npz and val_features_no_sad.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87371829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
